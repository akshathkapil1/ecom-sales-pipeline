# E-Commerce Sales Data ETL Pipeline

## Overview

This project implements a scalable and reliable ETL pipeline using **Databricks** and **PySpark** for processing e-commerce sales data. It is designed to clean, transform, and analyze raw data to provide actionable insights for business stakeholders.

---

## Problem Statement

The task is to process raw e-commerce datasets, enrich them with relevant information, and generate aggregate insights. The goal is to support business decisions with curated, high-quality data outputs.

### Source

ğŸ“ [Download the datasets](https://drive.google.com/drive/folders/1eWxfGcFwJJKAK0Nj4zZeCVx6gagPEEVc?usp=sharing)

---

## Tasks & Deliverables

### âœ… Raw Tables : Bronze Layer

- Load and store the raw data from each source dataset as-is.

### âœ… Cleaned and Standardized Tables : Silver Layer

- Apply transformations to remove invalid and duplicate records.
- Trim whitespace, fix casing, validate data types, and handle nulls.

Output:
  - silver.products
  - silver.customers
  - silver.orders

### âœ… Enriched Tables and Aggregated Tables : Gold Layer

- **Order Enriched Table**: Combines orders with:
  - Profit rounded to 2 decimal places
  - Customer name & country
  - Product category & subcategory

- Compute profit by:
  - Year
  - Product Category
  - Product Subcategory
  - Customer

Output:
  - gold.enriched_orders
  - gold.aggregated_profit

### âœ… SQL Aggregates (via Databricks SQL)
- Profit by Year
- Profit by Year + Product Category
- Profit by Customer
- Profit by Customer + Year

---

## Tech Stack

- **Platform**: Databricks (Azure)
- **Language**: Python 3, PySpark
- **Testing**: `pytest`
- **Orchestration**: Databricks Notebooks (modularized)

---

## ğŸ“ Directory Structure

ecom-sales-pipeline/src<br>
â”œâ”€â”€ etl/<br>
â”‚   â”œâ”€â”€ data_extractor.py       # Logic to load raw datasets<br>
â”‚   â”œâ”€â”€ data_standardizer.py    # Data cleaning and standardization<br>
â”‚   â”œâ”€â”€ data_transformer.py     # Data enrichment and transformations<br>
â”‚   â””â”€â”€ constants.py            # Application-wide constants<br>
â”œâ”€â”€ notebooks/<br>
â”‚   â””â”€â”€ ecom-sales.ipynb             # Main Databricks notebook entry point<br>
â”œâ”€â”€ tests/<br>
â”‚   â”œâ”€â”€ test_data_standardizer.py<br>
â”‚   â”œâ”€â”€ test_data_transformer.py<br>
â””â”€â”€ README.md                   # Project documentation<br>


